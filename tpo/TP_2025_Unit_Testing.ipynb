{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72632ef4-bff8-433d-a21d-e8d4b990282d",
   "metadata": {},
   "source": [
    "# TP Unit Testing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce4c04e-9e21-447e-8689-ba60cfc3cec6",
   "metadata": {},
   "source": [
    "|                 |                                                                                      |\n",
    "| --              | --                                                                                   |\n",
    "| **Universidad** | Universidad Nacional del Oeste                                                       |\n",
    "| **Carrera**     | Tec. Univ. en Tecnologías Web                                                        |\n",
    "| **Materia**     | Taller de Lenguajes                                                                  |\n",
    "| **Profesores**  | Mg. Ing. Pablo Pandolfo / Anta. Alex Andrada                                         |\n",
    "| **Alumnos**     | Grupo 3: Cuadros Karen, Nogueira Cristian, Castellino Gonzalo, Farias Gonzalo        |\n",
    "| **Fecha**       | Noviembre 2025                                                                       |\n",
    "|                 |                                                                                      |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434da4d-bd46-4d70-bcdc-38dd81934d2d",
   "metadata": {},
   "source": [
    "### ¿Qué son las pruebas unitarias?\n",
    "\n",
    "Las **pruebas unitarias** (**unit tests**) son tests que se enfocan en **verificar el correcto funcionamiento de la unidad más pequeña de código**, generalmente una **función, método o clase**, de manera aislada del resto del sistema.\n",
    "\n",
    "Su objetivo principal es detectar errores o comportamientos inesperados en cada unidad de forma temprana, antes de integrarla con otras partes del programa.\n",
    "\n",
    "---\n",
    "\n",
    "### ¿Para qué sirven?\n",
    "\n",
    "Las pruebas unitarias sirven para:\n",
    "\n",
    "- **Detectar errores de manera temprana:** Al probar unidades individuales, los fallos se localizan fácilmente.\n",
    "- **Garantizar la calidad del código:** Ayudan a mantener un código confiable y robusto.\n",
    "- **Facilitar cambios y refactorización:** Si modificás código, los tests aseguran que nada se rompa.\n",
    "- **Documentar el comportamiento esperado:** Cada test funciona como ejemplo de cómo debería funcionar la unidad.\n",
    "- **Reducir costos de mantenimiento:** Corregir errores tempranamente evita problemas mayores en producción.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c1332d-41d9-4bd8-a932-cc57b7457c21",
   "metadata": {},
   "source": [
    "### Caracteristicas\n",
    "Un buen test unitario se define por varias características esenciales que garantizan su eficacia y confiabilidad dentro del proceso de desarrollo de software.\n",
    "\n",
    "- ##### **Aislamiento**\n",
    "    Un unit test debe probar únicamente una unidad de código, sin depender de bases de datos, APIs externas, archivos u otros módulos. La idea es evaluar la función por sí sola, sin influencias externas.\n",
    "\n",
    "- ##### **Determinismo**\n",
    "    El resultado del test debe ser siempre el mismo, sin importar cuántas veces se ejecute o en qué entorno se corra. No debe depender de valores variables como la hora del sistema, la red o datos aleatorios sin control.\n",
    "\n",
    "- ##### **Rapidez**\n",
    "    Los tests unitarios deben ejecutarse en milisegundos. Como se corren constantemente durante el desarrollo, deben ser livianos y eficientes.\n",
    "\n",
    "- ##### **Simplicidad**\n",
    "    Cada test debe enfocarse en un solo comportamiento específico. No debe intentar validar muchos escenarios dentro del mismo bloque, ya que eso dificulta su lectura y mantenimiento.\n",
    "\n",
    "- ##### **Repetibilidad**\n",
    "    Un test unitario debe poder ejecutarse en cualquier momento sin configuraciones adicionales. No debería requerir que el desarrollador prepare datos manualmente ni que el entorno tenga configuraciones especiales.\n",
    "\n",
    "- ##### **Independencia**\n",
    "    Los tests no deben depender unos de otros. Cada uno debe poder ejecutarse por separado, sin necesidad de que otro test se ejecute antes o después.\n",
    "\n",
    "- ##### **Legibilidad**\n",
    "    Los tests deben ser claros y fáciles de entender. Su nombre y contenido deben indicar exactamente qué comportamiento están verificando. De esta manera, también funcionan como documentación del sistema.\n",
    "\n",
    "  ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e1e46-e039-4030-bbe0-6d3552035c82",
   "metadata": {},
   "source": [
    "### ¿Por qué hacer test unitarios con python?\n",
    "\n",
    "El ecosistema de pruebas de Python destaca por su simplicidad, flexibilidad y velocidad de desarrollo.\n",
    "\n",
    "El testing en Python ofrece varias ventajas importantes cuando lo comparamos con otros lenguajes de programación. La primera gran diferencia es la simplicidad de su sintaxis. En Python, los tests se escriben con pocas líneas y se leen de forma muy natural, casi como si fueran frases en lenguaje común. Esto facilita entender rápidamente qué se está probando y hace que escribir tests no se vuelva una tarea pesada, algo que sí puede pasar en lenguajes más verbosos como Java o C#.\n",
    "\n",
    "Python también destaca porque trae herramientas incluidas en la librería estándar, como unittest y unittest.mock. Esto significa que no necesitás instalar nada extra para empezar a hacer pruebas y crear mocks. En otros lenguajes, los mocks suelen requerir librerías externas, lo que agrega más configuración y dependencias al proyecto.\n",
    "Ademas no necesita compilarse para ejecutar tests. Esto hace que el ciclo de escribir, corregir y volver a probar sea mucho más rápido que en lenguajes compilados como Java, C# o C++.\n",
    "\n",
    "#### Ventajas\n",
    "1. Menos código, menos estructura obligatoria, y mucho más legible.\n",
    "2. Mocking integrado\n",
    "3. Velocidad sin compilación\n",
    "4. Ecosistema estable (pytest)\n",
    "5. Curva de aprendizaje\n",
    "6. Configuración inicial baja\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f448fc31-08ea-42e8-857f-5965da62ac8a",
   "metadata": {},
   "source": [
    "### Tipos de pruebas\n",
    "##### 1. Pruebas Funcionales\n",
    "- Verifican que una **función o método cumpla con su comportamiento esperado** según la especificación.\n",
    "- Ejemplo: una función `sumar(a, b)` debe devolver la suma correcta de `a` y `b`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "311d6f66-d16c-4e56-a14e-d2638dc5b5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "from unittest.mock import Mock\n",
    "\n",
    "def sumar(a, b):\n",
    "    return a + b\n",
    "\n",
    "class TestFuncionales(unittest.TestCase):\n",
    "    def test_sumar(self):\n",
    "        self.assertEqual(sumar(2, 3), 5)\n",
    "        self.assertEqual(sumar(-1, 1), 0)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    unittest.main(argv=[''], exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d2c4a7-8b3e-45dd-b081-3e4f1d666ad3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### 2. Pruebas de Excepciones o Errores\n",
    "- Se enfocan en comprobar que el código **maneje correctamente situaciones excepcionales**.\n",
    "- Ejemplo: una función que recibe un número positivo debe lanzar un error si recibe un número negativo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19feafb5-ee31-4be3-acad-050532d8f21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1f268b23e50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "# Función a probar\n",
    "def dividir(a, b):\n",
    "    if b == 0:\n",
    "        raise ValueError(\"No se puede dividir por cero\")\n",
    "    return a / b\n",
    "\n",
    "# Clase de test\n",
    "class TestExcepciones(unittest.TestCase):\n",
    "    def test_dividir_por_cero(self):\n",
    "        with self.assertRaises(ValueError):\n",
    "            dividir(10, 0)\n",
    "\n",
    "# Ejecutar solo esta prueba\n",
    "unittest.main(argv=[''], exit=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c480f9-da71-49af-9bcb-026f1a98a055",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### 3. Pruebas de Límite (Boundary Testing)\n",
    "- Se centran en verificar el comportamiento del código en **valores límite o extremos**.\n",
    "- Ejemplo: probar que una función acepte 0 y el valor máximo permitido sin fallar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "920111bb-c719-42fa-8efd-fd1d306af899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_edad_limite (__main__.TestLimite.test_edad_limite) ... ok\n",
      "test_edad_limite2 (__main__.TestLimite.test_edad_limite2) ... ok\n",
      "test_edad_limite3 (__main__.TestLimite.test_edad_limite3) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.004s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2a0e8adb240>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "def es_edad_valida(edad):\n",
    "    return 0 <= edad <= 120\n",
    "\n",
    "class TestLimite(unittest.TestCase):\n",
    "    def test_edad_limite(self):\n",
    "        self.assertTrue(es_edad_valida(0))\n",
    "        self.assertTrue(es_edad_valida(120))\n",
    "        self.assertFalse(es_edad_valida(-1))\n",
    "        self.assertFalse(es_edad_valida(121))\n",
    "    def test_edad_limite2(self):\n",
    "        self.assertTrue(es_edad_valida(0))\n",
    "        self.assertTrue(es_edad_valida(120))\n",
    "        self.assertFalse(es_edad_valida(-1))\n",
    "        self.assertFalse(es_edad_valida(121))\n",
    "\n",
    "unittest.main(defaultTest='TestLimite', argv=[''], verbosity=2, exit=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493645fb-303e-4ef0-a9e1-427e2552680d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### 4. Pruebas de Estado\n",
    "- Verifican cómo cambia el **estado interno de un objeto o clase** después de ejecutar una operación.\n",
    "- Ejemplo: un contador que aumenta su valor cada vez que se llama al método `incrementar()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f902189-9163-4469-ae4a-90b11e3b4748",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....\n",
      "----------------------------------------------------------------------\n",
      "Ran 4 tests in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1f268b23d50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "class Contador:\n",
    "    def __init__(self):\n",
    "        self.valor = 0\n",
    "    def incrementar(self):\n",
    "        self.valor += 1\n",
    "\n",
    "class TestEstado(unittest.TestCase):\n",
    "    def test_incrementar(self):\n",
    "        c = Contador()\n",
    "        c.incrementar()\n",
    "        self.assertEqual(c.valor, 1)\n",
    "        c.incrementar()\n",
    "        self.assertEqual(c.valor, 2)\n",
    "\n",
    "unittest.main(argv=[''], exit=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7dd34b-4eb1-4449-9b88-4edd4c73b66c",
   "metadata": {},
   "source": [
    "---\n",
    "##### 5. Pruebas de Mocking / Dependencias\n",
    "- Se usan **objetos simulados (mocks, stubs)** para aislar la unidad de sus dependencias externas.\n",
    "- Ejemplo: probar un método que envía correos sin realmente enviar emails, usando un objeto simulado.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e8572b4f-1d36-4316-8515-4f92e1d8b13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "......\n",
      "----------------------------------------------------------------------\n",
      "Ran 6 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x1f268254450>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "from unittest.mock import Mock\n",
    "\n",
    "class Correo:\n",
    "    def enviar(self, mensaje):\n",
    "        pass\n",
    "\n",
    "class Usuario:\n",
    "    def __init__(self, correo):\n",
    "        self.correo = correo\n",
    "    def notificar(self, mensaje):\n",
    "        self.correo.enviar(mensaje)\n",
    "\n",
    "class TestMocking(unittest.TestCase):\n",
    "    def test_notificar(self):\n",
    "        correo_mock = Mock()\n",
    "        usuario = Usuario(correo_mock)\n",
    "        usuario.notificar(\"Hola\")\n",
    "        correo_mock.enviar.assert_called_with(\"Hola\")\n",
    "\n",
    "unittest.main(argv=[''], exit=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f70da88-f1d7-401a-b408-f85855e933e0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### 6. Pruebas Parametrizadas\n",
    "- Permiten **probar la misma función con múltiples conjuntos de datos** automáticamente.\n",
    "- Ejemplo: probar la función `esPar(n)` con una lista de números positivos, negativos y cero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "72757e86-1a46-4ff2-94a0-d737955c365f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "....F\n",
      "======================================================================\n",
      "FAIL: test_varios_valores (__main__.TestParametrizadas.test_varios_valores) (valor=3)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Cris\\AppData\\Local\\Temp\\ipykernel_14912\\1927479964.py\", line 11, in test_varios_valores\n",
      "    self.assertEqual(es_par(valor), esperado)\n",
      "    ~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AssertionError: False != True\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.004s\n",
      "\n",
      "FAILED (failures=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x2a0e8adbac0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "def es_par(n):\n",
    "    return n % 2 == 0\n",
    "\n",
    "class TestParametrizadas(unittest.TestCase):\n",
    "    def test_varios_valores(self):\n",
    "        casos = [(2, True), (3, True), (0, True), (-4, True), (-5, False)]\n",
    "        for valor, esperado in casos:\n",
    "            with self.subTest(valor=valor):\n",
    "                self.assertEqual(es_par(valor), esperado)\n",
    "\n",
    "unittest.main(argv=[''], exit=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2ae0f0-e569-4c5b-ba29-8127c2f8f398",
   "metadata": {},
   "source": [
    "---\n",
    "## Herramientas y Frameworks de Pruebas en Python\n",
    "\n",
    "| Herramienta / Framework       | Tipo de pruebas que soporta                            | Ventajas principales                                         |\n",
    "|-------------------------------|--------------------------------------------------------|-------------------------------------------------------------|\n",
    "| **unittest**                  | Unitarias, integración, mocking                        | Incluido en Python, basado en clases, estable              \n",
    "| **pytest**                    | Unitarias, integración, parametrizadas, fixtures       | Sintaxis simple, flexible, extensible con plugins          |\n",
    "| **nose2**                     | Unitarias, integración                                 | Detecta tests automáticamente, evolución de nose          |\n",
    "| **doctest**                   | Unitarias simples dentro de docstrings                 | Permite documentación + pruebas en un mismo lugar         |\n",
    "| **Hypothesis**                | Pruebas basadas en propiedades                         | Genera automáticamente muchos casos, encuentra errores inesperados |\n",
    "| **Coverage**                  | Análisis de cobertura de código                        | Mide qué porcentaje del código está cubierto por tests     |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d5452f-10aa-484e-9b6c-ce0b66c7653c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pruebas Unitarias con Postman\n",
    "\n",
    "Postman es una herramienta muy popular para **probar APIs** de manera manual y automática. Aunque no es un framework de Python, permite realizar **pruebas unitarias orientadas a cada endpoint** de forma visual y fácil de configurar.\n",
    "\n",
    "### ¿Qué se puede probar con Postman?\n",
    "\n",
    "- **Códigos de estado HTTP** (200, 201, 400, 404, 500, etc.)\n",
    "- **Contenido de la respuesta** (JSON, XML, texto)\n",
    "- **Encabezados (headers)** de la respuesta\n",
    "- **Tiempo de respuesta**\n",
    "- **Autenticación y permisos** de los endpoints\n",
    "\n",
    "### Características avanzadas\n",
    "\n",
    "- **Variables**: Se pueden usar variables de entorno para cambiar URLs, tokens y datos dinámicos.\n",
    "\n",
    "- **Tests parametrizados**: Se puede probar el mismo endpoint con diferentes datos usando Collections Runner.\n",
    "\n",
    "- **Mocks**: Simular respuestas de la API para probar sin depender del servidor real.\n",
    "\n",
    "- **Automatización**: Integrar con CI/CD usando Newman (CLI de Postman).\n",
    "\n",
    "### En resumen\n",
    "- Postman permite hacer pruebas unitarias visuales de APIs sin necesidad de programar mucho.\n",
    "\n",
    "- Los tests son scripts en JavaScript dentro de cada request.\n",
    "\n",
    "- Se pueden automatizar con Newman y usar en entornos de desarrollo y producción.\n",
    "\n",
    "- Ideal para validar endpoints individualmente antes de integrarlos en aplicaciones más grandes.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e120c70-c956-4fc9-b64f-0a80800328d5",
   "metadata": {},
   "source": [
    "## Pruebas Unitarias para APIs en Python\n",
    "\n",
    "Las **pruebas unitarias orientadas a APIs** consisten en probar **cada endpoint o función que maneja solicitudes HTTP** de manera aislada, para garantizar que respondan correctamente a diferentes entradas.\n",
    "\n",
    "---\n",
    "\n",
    "#### Herramientas comunes para pruebas de APIs en Python: Pytest, Requests, Ipytest\n",
    "\n",
    "- Se combina la librería estándar `pytest` con `requests` para enviar solicitudes HTTP a la API.\n",
    "- Se puede combinar ipytest para testear dentro de jupiter.\n",
    "- Permite probar **respuestas, códigos de estado y contenido**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dbe94624-3b29-41da-b0f6-b74161c9d281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test_api.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile test_api.py\n",
    "# Ejemplo Pytest + Request GET\n",
    "import requests\n",
    "import pytest\n",
    "\n",
    "def test_get_user():\n",
    "    url = \"https://jsonplaceholder.typicode.com/users/1\"\n",
    "    response = requests.get(url)\n",
    "    assert response.status_code == 200\n",
    "    user_data = response.json()\n",
    "    assert user_data['id'] == 1\n",
    "    assert user_data['name'] == \"Leanne Graham\"\n",
    "    assert user_data['email'] == \"Sincere@april.biz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71eb9584-bcd6-4f69-9aa3-8102d00cb11f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts =============================\u001b[0m\n",
      "platform win32 -- Python 3.13.5, pytest-9.0.1, pluggy-1.6.0 -- C:\\Users\\Cris\\AppData\\Local\\Programs\\Python\\Python313\\python.exe\n",
      "cachedir: .pytest_cache\n",
      "rootdir: P:\\Proyectos\\VSC\\Jupyter\n",
      "plugins: anyio-4.11.0\n",
      "\u001b[1mcollecting ... \u001b[0mcollected 1 item\n",
      "\n",
      "test_api.py::test_get_user \u001b[32mPASSED\u001b[0m\u001b[32m                                        [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.55s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pytest test_api.py -v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fef6f7-ac2b-461b-b673-e82ae9983c19",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "56964c80-5472-4c29-95f8-1ee168bab5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m.\u001b[0m\u001b[32m                                                                                            [100%]\u001b[0m\n",
      "\u001b[32m\u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 0.23s\u001b[0m\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ExitCode.OK: 0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Con ipytest\n",
    "import ipytest\n",
    "import requests\n",
    "\n",
    "ipytest.autoconfig()\n",
    "\n",
    "def test_create_post():\n",
    "    \n",
    "    url = \"https://jsonplaceholder.typicode.com/posts\"\n",
    "    payload = {\n",
    "        'title': 'Mi Post de Pruebassss',\n",
    "        'body': 'Este es el contenido de mi post.',\n",
    "        'userId': 1\n",
    "    }\n",
    "    \n",
    "    response = requests.post(url, json=payload)\n",
    "\n",
    "    assert response.status_code == 201\n",
    "    \n",
    "    data_creada = response.json()\n",
    "    assert data_creada['title'] == 'Mi Post de Pruebassss'\n",
    "    assert data_creada['userId'] == 1\n",
    "    assert 'id' in data_creada\n",
    "    \n",
    "ipytest.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f613b677-cc8a-4df7-9bba-fd0c59967f8b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a7b71c9-3ab6-45bc-8ee9-ac543cacb80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Código de estado: 200\n",
      "Datos recibidos:\n",
      "{'id': 1, 'name': 'Leanne Graham', 'username': 'Bret', 'email': 'Sincere@april.biz', 'address': {'street': 'Kulas Light', 'suite': 'Apt. 556', 'city': 'Gwenborough', 'zipcode': '92998-3874', 'geo': {'lat': '-37.3159', 'lng': '81.1496'}}, 'phone': '1-770-736-8031 x56442', 'website': 'hildegard.org', 'company': {'name': 'Romaguera-Crona', 'catchPhrase': 'Multi-layered client-server neural-net', 'bs': 'harness real-time e-markets'}}\n",
      "\n",
      "¡Éxito! Todas las comprobaciones (asserts) pasaron.\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo solo con requests\n",
    "import requests\n",
    "\n",
    "url = \"https://jsonplaceholder.typicode.com/users/1\"\n",
    "response = requests.get(url)\n",
    "\n",
    "print(f\"Código de estado: {response.status_code}\")\n",
    "assert response.status_code == 200\n",
    "\n",
    "user_data = response.json()\n",
    "print(\"Datos recibidos:\")\n",
    "print(user_data)\n",
    "\n",
    "assert user_data['id'] == 1\n",
    "assert user_data['name'] == \"Leanne Graham\"\n",
    "\n",
    "print(\"\\n¡Éxito! Todas las comprobaciones (asserts) pasaron.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee173f9-e37f-4420-a0ee-7114cd1456cf",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
